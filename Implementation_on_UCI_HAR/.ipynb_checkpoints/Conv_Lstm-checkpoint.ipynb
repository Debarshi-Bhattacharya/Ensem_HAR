{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1828c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14870819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def load_file(filepath):\n",
    "    dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    "\n",
    "\n",
    "\n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    loaded = np.dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'C:/Users/bhatt/Desktop/Research_work/Dataset/UCI HAR Dataset/')\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'C:/Users/bhatt/Desktop/Research_work/Dataset/UCI HAR Dataset/')\n",
    "    \n",
    "    #zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    #one hot encode y\n",
    "    trainy_one_hot = to_categorical(trainy)\n",
    "    testy_one_hot = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, trainy_one_hot.shape, testX.shape, testy.shape, testy_one_hot.shape)\n",
    "    return trainX, trainy, trainy_one_hot, testX, testy, testy_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc594bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 1) (7352, 6) (2947, 128, 9) (2947, 1) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, trainy_one_hot, testX, testy, testy_one_hot = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de6cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy_one_hot.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70bfea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps, n_length = 4, 32\n",
    "trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b67858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):  \n",
    "  model =Sequential([\n",
    "    TimeDistributed(Conv1D(\n",
    "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5,7,9]),\n",
    "        activation='relu',\n",
    "        input_shape=(n_timesteps, n_features)\n",
    "    )),\n",
    "    TimeDistributed(Conv1D(\n",
    "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values = [3,5,7]),\n",
    "        activation='relu'\n",
    "    )),\n",
    "    TimeDistributed(Conv1D(\n",
    "        filters=hp.Int('conv_3_filter', min_value=32, max_value=64, step=16),\n",
    "        kernel_size=hp.Choice('conv_3_kernel', values = [3,5,7]),\n",
    "        activation='relu'\n",
    "    )),\n",
    "    TimeDistributed(Dropout(0.5)),\n",
    "    TimeDistributed(MaxPooling1D(pool_size=2)),\n",
    "    TimeDistributed(Flatten()),\n",
    "    LSTM(units=hp.Int('hidden_units',min_value=100,max_value=300,step=20), return_sequences=True),\n",
    "    Dropout(0.5,seed=0),\n",
    "    LSTM(units=hp.Int('hidden_units',min_value=100,max_value=300,step=20)),\n",
    "    Dropout(0.5, seed=1),\n",
    "    Dense(\n",
    "        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    Dense(n_outputs,activation='softmax')\n",
    "  ])\n",
    "  \n",
    "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02dddca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f6a4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_search=RandomSearch(build_model,\n",
    "                          objective='val_accuracy',\n",
    "                          max_trials=1,directory='output',project_name=\"HAR_ConvLstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd4d003b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 9\n",
      "conv_1_filter (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': None}\n",
      "conv_1_kernel (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [3, 5, 7, 9], 'ordered': True}\n",
      "conv_2_filter (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 64, 'step': 16, 'sampling': None}\n",
      "conv_2_kernel (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [3, 5, 7], 'ordered': True}\n",
      "conv_3_filter (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 64, 'step': 16, 'sampling': None}\n",
      "conv_3_kernel (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [3, 5, 7], 'ordered': True}\n",
      "hidden_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 100, 'max_value': 300, 'step': 20, 'sampling': None}\n",
      "dense_1_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d3948e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 01m 04s]\n",
      "val_accuracy: 0.6202918291091919\n",
      "\n",
      "Best val_accuracy So Far: 0.6202918291091919\n",
      "Total elapsed time: 00h 01m 04s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(trainX,trainy_one_hot,epochs=3,batch_size=32,validation_data= (testX,testy_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1fc5bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in output1\\HAR_ConvLstm\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 128\n",
      "conv_1_kernel: 9\n",
      "conv_2_filter: 64\n",
      "conv_2_kernel: 3\n",
      "conv_3_filter: 64\n",
      "conv_3_kernel: 3\n",
      "hidden_units: 160\n",
      "dense_1_units: 32\n",
      "learning_rate: 0.01\n",
      "Score: 0.6202918291091919\n"
     ]
    }
   ],
   "source": [
    "tuner_search.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9856f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner_search.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd836881",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "230/230 [==============================] - 20s 40ms/step - loss: 0.6554 - accuracy: 0.6551 - val_loss: 0.6968 - val_accuracy: 0.6281\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 7s 31ms/step - loss: 0.6666 - accuracy: 0.6557 - val_loss: 0.7151 - val_accuracy: 0.5959\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 7s 30ms/step - loss: 0.6909 - accuracy: 0.6406 - val_loss: 0.8440 - val_accuracy: 0.6040\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 7s 29ms/step - loss: 0.6744 - accuracy: 0.6481 - val_loss: 0.7035 - val_accuracy: 0.6064\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.6921 - accuracy: 0.6405 - val_loss: 0.6929 - val_accuracy: 0.6291\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 7s 32ms/step - loss: 0.6566 - accuracy: 0.6536 - val_loss: 0.7135 - val_accuracy: 0.5864\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 7s 28ms/step - loss: 0.8642 - accuracy: 0.5786 - val_loss: 1.2038 - val_accuracy: 0.4303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x250d710e5b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX,trainy_one_hot,epochs=10,validation_data= (testX,testy_one_hot), initial_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fded835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[491   0   0   0   5   0]\n",
      " [461   0   0   0  10   0]\n",
      " [400   0   0   0  20   0]\n",
      " [  6   0   0   0 485   0]\n",
      " [ 19   0   0   0 513   0]\n",
      " [ 54   0   0   0 219 264]]\n",
      "0.4302680692229386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.99      0.51       496\n",
      "           1       0.00      0.00      0.00       471\n",
      "           2       0.00      0.00      0.00       420\n",
      "           3       0.00      0.00      0.00       491\n",
      "           4       0.41      0.96      0.58       532\n",
      "           5       1.00      0.49      0.66       537\n",
      "\n",
      "    accuracy                           0.43      2947\n",
      "   macro avg       0.29      0.41      0.29      2947\n",
      "weighted avg       0.31      0.43      0.31      2947\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhatt\\anaconda3\\envs\\dLenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bhatt\\anaconda3\\envs\\dLenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bhatt\\anaconda3\\envs\\dLenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predy=model.predict(testX)\n",
    "predy=np.argmax(predy, axis=-1)\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "cm=confusion_matrix(testy,predy)\n",
    "print(cm)\n",
    "print(accuracy_score(testy,predy))\n",
    "print(classification_report(testy,predy))\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1ccd69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4119f5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dLenv",
   "language": "python",
   "name": "dlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
