{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966dacbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from numpy import dstack\n",
    "from keras.models import load_model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f09e55ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_file(filepath):\n",
    "    dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    "\n",
    "\n",
    "\n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    loaded = np.dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + '..//..//Dataset//UCI HAR Dataset//')\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + '..//..//Dataset//UCI HAR Dataset//')\n",
    "    \n",
    "    #zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    #one hot encode y\n",
    "    trainy_one_hot = to_categorical(trainy)\n",
    "    testy_one_hot = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, trainy_one_hot.shape, testX.shape, testy.shape, testy_one_hot.shape)\n",
    "    return trainX, trainy, trainy_one_hot, testX, testy, testy_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e52475e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 1) (7352, 6) (2947, 128, 9) (2947, 1) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, trainy_one_hot, testX, testy, testy_one_hot = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990b9f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train_one_hot,y_val_one_hot,y_train,y_val=train_test_split(trainX, trainy_one_hot, trainy,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f5d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps, n_length = 4, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ea9ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX3 = trainX.reshape((trainX.shape[0], n_steps, n_length,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d296dbb",
   "metadata": {},
   "source": [
    "## Loading Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83f4aeb",
   "metadata": {},
   "source": [
    "- **model1: 3levels on CNN (4layers in each)(takes 4input)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "512a2db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model(\"Models_h5//model1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb3758a",
   "metadata": {},
   "source": [
    "- **model2: 3levels on CNN (4layers in each) , parallaly 1LSTM layer (takes 5inputs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c892b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model(\"Models_h5//model2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f672c7c",
   "metadata": {},
   "source": [
    "- **model3: Timdistributed ConvLSTM(takes 1input)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b64fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = load_model(\"Models_h5//model3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4f7c8",
   "metadata": {},
   "source": [
    "- **model4: 2layered LSTM(takes 1input)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d0bb6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = load_model(\"Models_h5//model4.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfedc68",
   "metadata": {},
   "source": [
    "##  Running the member models to make predictions on the validation set, and create a new training set with the resulting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "760a1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps, n_length = 4, 32\n",
    "X_val3 = X_val.reshape((X_val.shape[0], n_steps, n_length,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86228b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackX = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aac68b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output model1\n",
    "yhat = model1.predict([X_val,X_val,X_val,X_val], verbose=0)\n",
    "yhat=np.argmax(yhat, axis=-1)\n",
    "stackX =yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "843af5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output model2\n",
    "yhat = model2.predict([X_val,X_val,X_val,X_val,X_val], verbose=0)\n",
    "yhat=np.argmax(yhat, axis=-1)\n",
    "stackX = dstack((stackX, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db60d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output model3\n",
    "\n",
    "yhat = model3.predict(X_val3, verbose=0)\n",
    "yhat=np.argmax(yhat, axis=-1)\n",
    "stackX = dstack((stackX, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fa1d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output model4\n",
    "yhat = model4.predict(X_val, verbose=0)\n",
    "yhat=np.argmax(yhat, axis=-1)\n",
    "stackX = dstack((stackX, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7bf3f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Output model5\n",
    "# yhat = model5.predict([X_val3,X_val3,X_val3] ,verbose=0)\n",
    "# yhat=np.argmax(yhat, axis=-1)\n",
    "# stackX = dstack((stackX, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0836905f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2206, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55283f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackX = stackX.reshape((stackX.shape[0]*stackX.shape[1],stackX.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b61dc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2206, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackX.shape####it is the training set of the ensembling classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c456313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2206, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0536edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier(n_estimators=10,criterion='gini',\n",
    "                             max_features='log2',min_samples_leaf=1,min_samples_split=7,max_depth=560,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5643fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_1D=np.ravel(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97eda054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=560, max_features='log2', min_samples_split=7,\n",
       "                       n_estimators=10, random_state=100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(stackX,y_val_1D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb0da27",
   "metadata": {},
   "source": [
    "##  Now evaluate the ensemble on the test set:\n",
    "#### Create stacked model input dataset as outputs from the ensemble;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc2ad5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackX = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27044cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps, n_length = 4, 32\n",
    "testX3 = testX.reshape((testX.shape[0], n_steps, n_length,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ff468f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output model1\n",
    "yhat = model1.predict([testX,testX,testX,testX], verbose=0)\n",
    "yhat=np.argmax(yhat, axis=-1)\n",
    "stackX = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9185b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output model2\n",
    "yhat = model2.predict([testX,testX,testX,testX,testX], verbose=0)\n",
    "yhat=np.argmax(yhat, axis=-1)\n",
    "stackX = dstack((stackX, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a23d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output model3\n",
    "\n",
    "yhat = model3.predict(testX3, verbose=0)\n",
    "yhat=np.argmax(yhat, axis=-1)\n",
    "stackX = dstack((stackX, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "381c5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output model4\n",
    "yhat = model4.predict(testX, verbose=0)\n",
    "yhat=np.argmax(yhat, axis=-1)\n",
    "stackX = dstack((stackX, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5678525e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2947, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2686783",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackX = stackX.reshape((stackX.shape[0]*stackX.shape[1],stackX.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4b8fe28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7eef483",
   "metadata": {},
   "outputs": [],
   "source": [
    "predy=rfc.predict(stackX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b1dda32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[493   1   2   0   0   0]\n",
      " [  2 459  10   0   0   0]\n",
      " [  1   3 416   0   0   0]\n",
      " [  0   2   3 408  77   1]\n",
      " [  0   0   0  33 499   0]\n",
      " [  0   0   0   0   0 537]]\n",
      "0.9541907024092298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       496\n",
      "           1       0.99      0.97      0.98       471\n",
      "           2       0.97      0.99      0.98       420\n",
      "           3       0.93      0.83      0.88       491\n",
      "           4       0.87      0.94      0.90       532\n",
      "           5       1.00      1.00      1.00       537\n",
      "\n",
      "    accuracy                           0.95      2947\n",
      "   macro avg       0.96      0.95      0.95      2947\n",
      "weighted avg       0.96      0.95      0.95      2947\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm=confusion_matrix(testy,predy)\n",
    "print(cm)\n",
    "print(acc(testy,predy))\n",
    "print(classification_report(testy,predy))\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f6068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325fc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b88909b7410d2ec5c519e3dda149c3970124874d7da8616ec07adb4aadd07c54"
  },
  "kernelspec": {
   "display_name": "dLenv",
   "language": "python",
   "name": "dlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
